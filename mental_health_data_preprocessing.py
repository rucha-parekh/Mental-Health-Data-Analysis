# -*- coding: utf-8 -*-
"""Mental Health Data Preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10KOjk7rIeuXMKCPJXc_Und-BV3NWXAPV

# **MENTAL HEALTH DATA ANALYSIS: PREPROCESSING**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re

"""## **Cleaning Dataset**"""

df=pd.read_csv("/content/mentalhealth_dirty.csv")
df.head()

df.info()
df.nunique()

"""## **Dropping columns**"""

null_counts = df.isnull().sum()
print(null_counts)
print("proportion of null values for each column")
print(df.isnull().sum()/len(df))
print("since for any column proportion of null values is not > 0.5 , we need not drop any column")

"""## **Removing duplicates**"""

#checking for duplicate rows:
duplicate_rows = df.duplicated()
num_duplicates = duplicate_rows.sum()
print("Number of duplicate rows:", num_duplicates)

print("Number of rows before removing duplicates:", len(df))
df = df.drop_duplicates()

# Print the number of row after removing duplicates
print("Number of rows after removing duplicates:", len((df)))
df.to_csv('mental_health_preprocessed.csv', index=False)
df1=pd.read_csv("/content/mental_health_preprocessed.csv")
duplicate_rows1 = df1.duplicated()
num_duplicates1 = duplicate_rows1.sum()
print("Number of duplicate rows:", num_duplicates1)

"""## **Filling null values**"""

#filling Null values
df['Gender'].fillna('Other', inplace=True)
df['Occupation'].fillna('Unemployed', inplace=True)
df['Social_Weakness'].fillna('Not_Mentioned', inplace=True)
df['Work_Interest'].fillna('Not_Mentioned', inplace=True)
df['Days_Indoors'].fillna('Not_Mentioned', inplace=True)
df['Growing_Stress'].fillna('Not_Mentioned', inplace=True)
df['Weight_Change'].fillna('Not_Mentioned', inplace=True)
df['Mood_Swings'].fillna('Havent_Noticed', inplace=True)
df['Mental_Health_History'].fillna('Not_Mentioned', inplace=True)
df['Changes_Habits'].fillna('Havent_Noticed', inplace=True)
df['Quarantine_Frustrations'].fillna('Not_Mentioned', inplace=True)
df['Coping_Struggles'].fillna('Not_Mentioned', inplace=True)

#dropping rows where Age isnt mentioned
df = df.dropna(subset=['Age'])

null_counts = df.isnull().sum()
print(null_counts)
df.head()
df.to_csv('mental_health_preprocessed.csv', index=False)

"""## **Outliers (Detection and Removal)**"""

columns_of_interest = ['Growing_Stress', 'Quarantine_Frustrations', 'Changes_Habits','Mental_Health_History','Weight_Change','Coping_Struggles','Work_Interest','Social_Weakness']
df[columns_of_interest] = df[columns_of_interest].applymap(lambda x: x.upper())

standardized_values = ['YES', 'NO', 'MAYBE', 'NOT_MENTIONED','HAVENT_NOTICED','HIGH','LOW','MEDIUM']

outlier_rows = df[df[columns_of_interest].applymap(lambda x: x.upper() not in standardized_values).any(axis=1)]

print("Outlier values:")
print(outlier_rows)

# Drop filtered rows from DataFrame
cleaned_df = df.drop(outlier_rows.index)

print("\nNumber of rows before filtering:", len(df))
print("Number of rows after filtering:", len(cleaned_df))
cleaned_df.to_csv('mental_health_preprocessed.csv',index=False)

df=cleaned_df
print(df['Age'].value_counts())
print(df['Growing_Stress'].value_counts())

"""## **Exploratory data analysis**"""

#showing prevalent patterns using heatmap
heatmap_data = df.groupby(['Age', 'Growing_Stress']).size().unstack(fill_value=0)
plt.figure(figsize=(10, 6))
sns.heatmap(heatmap_data, annot=True, cmap='Greens', fmt='g')
plt.title('Heatmap of Age vs Growing Stress')
plt.xlabel('Growing_Stress')
plt.ylabel('Age')
plt.show()
df.head()
df.to_csv('mental_health_preprocessed.csv', index=False)

"""## **plotting pie chart of male and female ratio.**"""

import matplotlib.pyplot as plt


gender_counts = df['Gender'].value_counts()

# Plotting
plt.figure(figsize=(8, 6))
plt.pie(gender_counts, labels=gender_counts.index, autopct='%1.1f%%', startangle=140)
plt.title('Gender Distribution')
plt.axis('equal')
plt.show()